{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09491622",
   "metadata": {},
   "source": [
    "# 爬取 PTT CAR 版 NISSAN 相關討論文章,並進行輿情分析\n",
    "在學習網頁爬蟲相關資源時，發現到大多數的文章僅著重在網頁爬蟲技術分享。輿情分析的部分，免費的中文學習資源較少，大多數以收費課程之形式存在。\n",
    "\n",
    "因此希望透過此專案可以將自己的實作過程記錄下來，並將學習的結果分享給大家。 這邊僅針對語法概念及目的進行說明，完整之語法執行結果大家可藉由此專案資料夾內之.ipynb檔做更進一步的了解。\n",
    "\n",
    "本專案旨在透過網頁爬蟲技巧收集 PTT Car 版中有關 Nissan 的討論文章，並透過輿情分析探索社會大眾對於 Nissan 相關主題的意見與情感傾向。 以下為本專案之大綱，後續將於每段步驟進行介紹並提供示範語法\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be6216a",
   "metadata": {},
   "source": [
    "# 環境安裝\n",
    "本專案使用 Python3 並且會使用 pip 來安裝所需的套件。以下是需要安裝的套件：\n",
    "\n",
    "beautifulsoup4：主要功能就是可以全面解析 HTML 或 XML 的架構。\n",
    "\n",
    "requests：用於發送與接收 HTTP 請求及回應。\n",
    "\n",
    "pandas：進行資料處理和資料分析的工具"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23ce922b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (4.12.2)\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (2.28.1)\n",
      "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (1.3.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from beautifulsoup4) (2.4.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from requests) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from requests) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from requests) (1.26.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from requests) (2023.7.22)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from pandas) (1.21.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from pandas) (2021.1)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install beautifulsoup4 requests pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b2e7a5",
   "metadata": {},
   "source": [
    "# 套件匯入\n",
    "首先，開發過程有時會忘記到底先前有沒有匯入過想使用的套件，導致重複在不同地方 import 一樣的套件進來，因此如果要使用之套件數量不多時，可以先將會使用到的套件一次匯入，避免讓 import 語法分散在不同段落中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "794d33ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request as request \n",
    "import bs4\n",
    "import csv\n",
    "from datetime import datetime\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96fee49c",
   "metadata": {},
   "source": [
    "# 讀取網站資料\n",
    "在進行網頁爬蟲時，我們會透過模擬瀏覽器發送 HTTP 請求獲取 PTT CAR 版中包含指定關鍵字的文章列表的 HTML 內容。這個函式會返回一個 response 物件，裡頭包含了網頁的回應內容。接著我們使用 BeautifulSoup 解析這個 HTML 內容，方便後續的資料提取。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d151e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#定義了要搜索的關鍵字，這裡以'Nissan'為例，可以根據需求調整為其他品牌或是使用迴圈撈取多品牌的結果。\n",
    "search_keyword = 'Nissan'\n",
    "\n",
    "#建立了目標網頁的URL，其中因爲PTT每頁有文章上限，因此透過頁面編號（page）這個參數，後續以迴圈方式獲取多頁目標網頁的內容。\n",
    "src='https://www.ptt.cc/bbs/car/search?page=' + str(page) + '&q='+ search_keyword\n",
    "\n",
    "#有些網站會檢查 User-Agent 以確保請求是由瀏覽器發出的，因此這裡模擬了 Chrome 瀏覽器的 User-Agent。\n",
    "requestUA=request.Request(src, headers={\n",
    "    \"User-Agent\":\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/88.0.4324.182 Safari/537.36\"\n",
    "})\n",
    "\n",
    "#打開 URL 並發送 HTTP 請求。使用 with 關鍵字可以確保在程式碼區塊結束時關閉資源，這邊也可以使用 requests.get 直接發送 GET 請求。\n",
    "with request.urlopen(requestUA) as response:\n",
    "    data=response.read().decode(\"utf-8\")\n",
    "\n",
    "#讓BeautifulSoup協助解析HTML格式文件\n",
    "root=bs4.BeautifulSoup(data, \"html.parser\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b4b041",
   "metadata": {},
   "source": [
    "# 撈取特定網站內容\n",
    "接著為了確認是否可以順利取得網頁的資訊，透過解析網頁的標籤位置，印出看板標題及文章標題。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b5cbb5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nissan - car - 批踢踢實業坊\n",
      "[新聞] Nissan「全新電動休旅」準備導入台灣！續航力最高610km\n",
      "[菜單] NISSAN SENTRA尊爵智駕版\n",
      "[電車] Nissan Ariya \n",
      "[新聞]不是特斯拉,日本最熱賣電動車Nissan Sakura「人人都買得起」!\n",
      "Re: [討論] Nissan的車子484值得買啊\n",
      "[討論] Nissan的車子484值得買啊\n",
      "[討論] Nissan caravan 露營車發表\n",
      "[分享] Nissan 電動概念車\n",
      "[新聞] 改款「新Nissan Sentra」台灣現身！有望\n",
      "Re: [新聞] 新車發表NISSAN KICKS e-POWER\n",
      "Re: [心得] Nissan Kicks e-power 短程試駕體驗分享\n",
      "[問題] Nissan的這是什麼按鍵？\n",
      "[心得] Nissan Kicks e-power 短程試駕體驗分享\n",
      "Re: [新聞] 新車發表NISSAN KICKS e-POWER\n",
      "[菜單] NISSAN KICKS 旗艦版\n",
      "[新聞] Nissan 小改款 X-Trail 意外提前曝光！\n",
      "Re: [新聞] 104.9萬 全新NISSAN KICKS e-POWER\n",
      "[新聞] 新車發表NISSAN KICKS e-POWER\n",
      "[菜單] Nissan X-trail輕油電旗艦榮耀版\n",
      "[新聞] 比亞迪在日本賣不好？他們更愛這款50萬級距的Nissan Sakura\n"
     ]
    }
   ],
   "source": [
    "#尋找\"title\"標籤字串，印出看板標題\n",
    "print(root.title.string)\n",
    "\n",
    "#尋找所有class=\"title\"的div標籤，印出文章標題\n",
    "titles=root.find_all(\"div\", class_=\"title\") \n",
    "for title in titles:\n",
    "    if title.a != None: #只印出未被刪除的文章\n",
    "        print(title.a.string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "812b8560",
   "metadata": {},
   "source": [
    "# 取得文章連結\n",
    "接著為了後續可以透過迴圈取得每篇文章的內容、作者、推文等資訊，因此可以先把文章連結事先撈取出來並存在一個空的陣列中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0fb258d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://www.ptt.cc/bbs/car/M.1701136264.A.E47.html', 'https://www.ptt.cc/bbs/car/M.1700832199.A.506.html', 'https://www.ptt.cc/bbs/car/M.1699346704.A.19F.html', 'https://www.ptt.cc/bbs/car/M.1698981078.A.EBE.html', 'https://www.ptt.cc/bbs/car/M.1698466656.A.BAD.html', 'https://www.ptt.cc/bbs/car/M.1698388504.A.40F.html', 'https://www.ptt.cc/bbs/car/M.1698386424.A.210.html', 'https://www.ptt.cc/bbs/car/M.1698385231.A.FCD.html', 'https://www.ptt.cc/bbs/car/M.1698366402.A.8FE.html', 'https://www.ptt.cc/bbs/car/M.1698090594.A.0DE.html', 'https://www.ptt.cc/bbs/car/M.1698031323.A.C2C.html', 'https://www.ptt.cc/bbs/car/M.1698026322.A.5D2.html', 'https://www.ptt.cc/bbs/car/M.1697995870.A.273.html', 'https://www.ptt.cc/bbs/car/M.1697945931.A.F16.html', 'https://www.ptt.cc/bbs/car/M.1697466809.A.309.html', 'https://www.ptt.cc/bbs/car/M.1697295225.A.130.html', 'https://www.ptt.cc/bbs/car/M.1696236980.A.406.html', 'https://www.ptt.cc/bbs/car/M.1696218471.A.30F.html', 'https://www.ptt.cc/bbs/car/M.1695452260.A.AB6.html', 'https://www.ptt.cc/bbs/car/M.1695302662.A.E8B.html']\n"
     ]
    }
   ],
   "source": [
    "#尋找所有class=\"r-ent\"的div標籤，印出文章連結\n",
    "rent = root.find_all('div',class_='r-ent')\n",
    "\n",
    "#建立一個空的陣列，把抓到的文章連結一個一個添加進去\n",
    "link=[]\n",
    "for title in rent:\n",
    "    #由於有些被刪除的文章會抓不到連結，所以把抓不到被刪除的文章濾掉\n",
    "    if title.a != None:\n",
    "        link.append(\"https://www.ptt.cc\"+title.a.get(\"href\"))\n",
    "print(link)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "698a56c0",
   "metadata": {},
   "source": [
    "# 依序爬取每篇文章之標題、作者、日期、內文、推文\n",
    "接著透過迴圈取得多頁文章的內容、作者、推文等資訊，由於後續希望將所有爬取的結果一筆一筆加進 DataFrame 並匯出成 csv 檔，因此我會把爬取到的資訊分別存在不同的陣列中，再 append 到 DataFrame 裡頭存放。\n",
    "\n",
    "結合前面的步驟，最後完成的程式語法如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b61915a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nissan - car - 批踢踢實業坊\n",
      "[新聞] Nissan「全新電動休旅」準備導入台灣！續航力最高610km\n",
      "[菜單] NISSAN SENTRA尊爵智駕版\n",
      "[電車] Nissan Ariya \n",
      "[新聞]不是特斯拉,日本最熱賣電動車Nissan Sakura「人人都買得起」!\n",
      "Re: [討論] Nissan的車子484值得買啊\n",
      "[討論] Nissan的車子484值得買啊\n",
      "[討論] Nissan caravan 露營車發表\n",
      "[分享] Nissan 電動概念車\n",
      "[新聞] 改款「新Nissan Sentra」台灣現身！有望\n",
      "Re: [新聞] 新車發表NISSAN KICKS e-POWER\n",
      "Re: [心得] Nissan Kicks e-power 短程試駕體驗分享\n",
      "[問題] Nissan的這是什麼按鍵？\n",
      "[心得] Nissan Kicks e-power 短程試駕體驗分享\n",
      "Re: [新聞] 新車發表NISSAN KICKS e-POWER\n",
      "[菜單] NISSAN KICKS 旗艦版\n",
      "[新聞] Nissan 小改款 X-Trail 意外提前曝光！\n",
      "Re: [新聞] 104.9萬 全新NISSAN KICKS e-POWER\n",
      "[新聞] 新車發表NISSAN KICKS e-POWER\n",
      "[菜單] Nissan X-trail輕油電旗艦榮耀版\n",
      "[新聞] 比亞迪在日本賣不好？他們更愛這款50萬級距的Nissan Sakura\n"
     ]
    }
   ],
   "source": [
    "#建立一個空的 DataFrame，後續會一筆一筆將爬取到的資料加進 DataFrame \n",
    "dataset = pd.DataFrame()\n",
    "\n",
    "#建立迴圈，可爬取多頁內容\n",
    "for page in range(1,2): #可依需求調整要爬取的頁數\n",
    "    search_keyword = 'Nissan' #可依需求調整關鍵字\n",
    "    #模擬 Chrome 瀏覽器的 User-Agent\n",
    "    src='https://www.ptt.cc/bbs/car/search?page=' + str(page) + '&q='+ search_keyword \n",
    "    requestUA=request.Request(src, headers={\n",
    "        \"User-Agent\":\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/88.0.4324.182 Safari/537.36\"\n",
    "    })\n",
    "    with request.urlopen(requestUA) as response:\n",
    "        data=response.read().decode(\"utf-8\")\n",
    "    root=bs4.BeautifulSoup(data, \"html.parser\") #讓BeautifulSoup協助解析HTML格式文件\n",
    "    #尋找\"title\"標籤字串，印出看板標題\n",
    "    print(root.title.string)\n",
    "\n",
    "    #尋找所有class=\"title\"的div標籤，印出文章標題\n",
    "    titles=root.find_all(\"div\", class_=\"title\") \n",
    "    for title in titles:\n",
    "        if title.a != None: #只印出未被刪除的文章\n",
    "            print(title.a.string)\n",
    "\n",
    "    #抓取看板文章的連結\n",
    "    rent = root.find_all('div',class_='r-ent')\n",
    "    #建立一個空的陣列，把抓到的文章連結一個一個添加進去\n",
    "    link=[]\n",
    "    for title in rent:\n",
    "        #由於有些被刪除的文章會抓不到連結，所以把抓不到被刪除的文章濾掉\n",
    "        if title.a != None:\n",
    "            link.append(\"https://www.ptt.cc\"+title.a.get(\"href\"))\n",
    "    #print(link)\n",
    "\n",
    "    #透過文章連結，抓取文章內容\n",
    "    for websites in link:\n",
    "        requestUA=request.Request(websites, headers={\n",
    "        \"User-Agent\":\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/88.0.4324.182 Safari/537.36\"\n",
    "        })\n",
    "        with request.urlopen(requestUA) as response:\n",
    "            data=response.read().decode(\"utf-8\")\n",
    "        root=bs4.BeautifulSoup(data, \"html.parser\") #讓BeautifulSoup協助解析HTML格式文件\n",
    "\n",
    "        header = root.find_all('span','article-meta-value')\n",
    "        if header != []:\n",
    "\n",
    "        # 作者\n",
    "            author = header[0].text\n",
    "        #可用此語法印出作者:print(\"Author : \"+ author+'\\n')\n",
    "\n",
    "        # 日期\n",
    "            date = header[3].text\n",
    "        #可用此語法印出日期:print(\"Date : \"+ date+'\\n')\n",
    "\n",
    "        #文章主題\n",
    "        titles=root.find_all(\"div\", id_=\"main-content\") \n",
    "        for title in titles:\n",
    "            if title.a != None: #如果標題包含a標籤 (沒有被刪除), 印出來\n",
    "                print(title.a.string)\n",
    "\n",
    "        #文章內容\n",
    "        main_container = root.find(id='main-container')\n",
    "        # 把所有文字都抓出來\n",
    "        if main_container != \" \":\n",
    "            all_text = main_container.text\n",
    "            # 把整個內容切割透過 \"-- \" 切割成2個陣列\n",
    "            pre_text = all_text.split('--')[0]\n",
    "\n",
    "            # 把每段文字 根據 '\\n' 切開\n",
    "            texts = pre_text.split('\\n')\n",
    "            # 如果你爬多篇你會發現 \n",
    "            contents = texts[2:]\n",
    "            # 內容\n",
    "            content = '\\n'.join(contents)\n",
    "\n",
    "        #可用此語法印出文章內容:print(content)\n",
    "\n",
    "        #推文\n",
    "        pushs=root.find_all(class_=\"f3 push-content\") \n",
    "        #可用此語法印出推文:print(pushs)\n",
    "\n",
    "        #推文ID\n",
    "        push_userid=root.find_all(class_=\"f3 hl push-userid\")\n",
    "        #可用此語法印出推文ID:print(push_userid)\n",
    "\n",
    "        #將推文ID存入空的陣列，排除掉已被刪除的推文\n",
    "        id=[]\n",
    "        for userid in push_userid:\n",
    "            if userid != None: \n",
    "                id.append(userid.string)\n",
    "        #可用此語法印出結果:print(userid.string) \n",
    "\n",
    "        #將推文內容存入空的陣列，排除掉已被刪除的推文\n",
    "        comment=[]\n",
    "        for push in pushs:\n",
    "            if push != None: \n",
    "                comment.append(push.string)\n",
    "        #可用此語法印出結果:print(push.string) \n",
    "\n",
    "        #為提升可讀性，將推文ID跟內容用迴圈整合在一起，存入空的陣列，排除掉已被刪除的推文\n",
    "        id_comment=[]\n",
    "        for i in range(len(id)):\n",
    "            if id[i] and comment[i] != None:\n",
    "                id_comment.append(id[i]+comment[i])\n",
    "            #print(id_comment)\n",
    "\n",
    "        # 由於PTT留言會有字數限制,因此這邊會針對留言進行加工,將相同帳號的留言合併\n",
    "        comments = id_comment\n",
    "\n",
    "        # 將留言合併\n",
    "        merged_comments = defaultdict(list)\n",
    "\n",
    "        for comment in comments:\n",
    "            # 使用冒號分割帳號和留言內容\n",
    "            parts = comment.split(':')\n",
    "            if len(parts) == 2:\n",
    "                username = parts[0].strip()\n",
    "                message = parts[1].strip()\n",
    "\n",
    "                # 將留言加入字典中的相應帳號\n",
    "                merged_comments[username].append(message)\n",
    "                \n",
    "        # 將合併的留言以迴圈加進陣列中\n",
    "        formatted_comments = []\n",
    "        for username, messages in merged_comments.items():\n",
    "            formatted_comments.append(f\"{username} : {''.join(messages)}\")\n",
    "\n",
    "        #可用此語法印出合併後的留言\n",
    "        #for comment in formatted_comments:\n",
    "            #print(comment)\n",
    "            \n",
    "        # 由於後續分析僅著重整體輿論方向,不針對留言對象進行分析,故僅把留言內容輸出\n",
    "        merged_comments = []\n",
    "\n",
    "        for comment in formatted_comments:\n",
    "            # 使用冒號分割帳號和留言內容\n",
    "            parts = comment.split(':')\n",
    "            if len(parts) == 2:\n",
    "                username = parts[0].strip()\n",
    "                message = parts[1].strip()\n",
    "                merged_comments.append(message)\n",
    "\n",
    "        merged_comment= '\\n'.join(merged_comments)\n",
    "\n",
    "        dataset = dataset.append(pd.DataFrame(data={'i': page,\n",
    "                                                    'date':date,\n",
    "                                                    'title':title.a.string,\n",
    "                                                    'link':websites,\n",
    "                                                    'author':author,\n",
    "                                                    'content':content,\n",
    "                                                    'comment':merged_comment\n",
    "                                                   }, index = [0]), ignore_index = True)\n",
    "\n",
    "#將 DataFrame 匯出成csv，可自行調整路徑跟名稱\n",
    "path='希望存放的路徑'\n",
    "dataset.to_csv(path + '/nissan_web_crawler.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "928f8d92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------push comment---------------\n",
      "\n",
      "[]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
